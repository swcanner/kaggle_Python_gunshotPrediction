{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/audio-binary-classification/train_data.npy\n",
      "/kaggle/input/audio-binary-classification/train_labels.csv\n",
      "/kaggle/input/audio-binary-classification/sample_submission.csv\n",
      "/kaggle/input/audio-binary-classification/test_data.npy\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Lambda, Input\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling2D, MaxPooling1D, LeakyReLU\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs loaded\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load('/kaggle/input/audio-binary-classification/train_data.npy');\n",
    "test_data = np.load('/kaggle/input/audio-binary-classification/test_data.npy');\n",
    "\n",
    "\n",
    "print(\"inputs loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3999, 44100)\n",
      "(3999, 44100, 1)\n"
     ]
    }
   ],
   "source": [
    "#Scale and Reshape\n",
    "train_data = train_data.astype('float32');\n",
    "test_data = test_data.astype('float32');\n",
    "\n",
    "#Normalize Data\n",
    "#train_data /= np.amax(test_data);\n",
    "#test_data /= np.amax(test_data);\n",
    "\n",
    "print(train_data.shape);\n",
    "\n",
    "train_data = train_data.reshape(-1,44100,1);\n",
    "test_data = test_data.reshape(-1,44100,1);\n",
    "\n",
    "input_shape = train_data.shape;\n",
    "print(input_shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 0 1 0]\n",
      "(3999,)\n"
     ]
    }
   ],
   "source": [
    "#Look at CSV and store as array\n",
    "train_labels = pd.read_csv(\"/kaggle/input/audio-binary-classification/train_labels.csv\");\n",
    "train_labels = train_labels.values;\n",
    "train_labels = train_labels[:,1];\n",
    "print(train_labels[:10]);\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data made noisey\n"
     ]
    }
   ],
   "source": [
    "#Modify data\n",
    "x_data = np.zeros( (train_data.shape[0] * 2 + 250, train_data.shape[1],1) );\n",
    "y_data = np.zeros( (train_labels.shape[0] * 2 + 250))\n",
    "\n",
    "x_data[:3999,:,0] = train_data[:3999,:,0];\n",
    "y_data[:3999] = train_labels[:3999];\n",
    "\n",
    "for a in range(train_data.shape[0]):\n",
    "    s = np.random.normal(1,.02,44100);\n",
    "    x_data[a+3999,:,0] = np.multiply(x_data[a,:,0],s);\n",
    "    y_data[a+3999] = train_labels[a];\n",
    "        \n",
    "b = 0;\n",
    "\n",
    "for a in range(train_data.shape[0]):\n",
    "    if(train_labels[a] == 1):\n",
    "        s = np.random.normal(1,.02,44100);\n",
    "        x_data[2*3999+b,:,0] = np.multiply(x_data[a,:,0],s);\n",
    "        y_data[2*3999+b] = train_labels[a];\n",
    "        b += 1;\n",
    "    if(b >= 250):\n",
    "        break;\n",
    "        \n",
    "print(\"data made noisey\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00110629 0.00221578 0.00401346 ... 0.02375466 0.01968718 0.01686463]\n",
      "[0.00109889 0.00225888 0.00400161 ... 0.02358773 0.01977906 0.01693984]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[1,:,0]);\n",
    "print(x_data[4000,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 44091, 64)         704       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 44091, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 11022, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11022, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 11015, 64)         32832     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 11015, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1835, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1835, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1831, 64)          20544     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1831, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 228, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 228, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 14592)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 80)                1167440   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 81        \n",
      "=================================================================\n",
      "Total params: 1,221,601\n",
      "Trainable params: 1,221,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create convolution neural network\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, kernel_size=(10),\n",
    "                 input_shape=(44100,1)))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Dropout(0.33))\n",
    "\n",
    "model.add(Conv1D(64, (8)))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(MaxPooling1D(pool_size=(6)))\n",
    "model.add(Dropout(0.33))\n",
    "\n",
    "model.add(Conv1D(64, (5)))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Dropout(0.33))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(80))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(Dropout(0.33))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model\n",
    "sgd = optimizers.SGD(lr=.01);\n",
    "model.compile(loss='MSE', \n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "8248/8248 [==============================] - 18s 2ms/step - loss: 0.1270 - acc: 0.8491\n",
      "Epoch 2/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0990 - acc: 0.8674\n",
      "Epoch 3/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0815 - acc: 0.8977\n",
      "Epoch 4/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0745 - acc: 0.9073\n",
      "Epoch 5/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0717 - acc: 0.9085\n",
      "Epoch 6/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0705 - acc: 0.9089\n",
      "Epoch 7/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0688 - acc: 0.9121\n",
      "Epoch 8/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0674 - acc: 0.9126\n",
      "Epoch 9/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0662 - acc: 0.9132\n",
      "Epoch 10/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0649 - acc: 0.9139\n",
      "Epoch 11/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0632 - acc: 0.9163\n",
      "Epoch 12/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0619 - acc: 0.9178\n",
      "Epoch 13/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0611 - acc: 0.9179\n",
      "Epoch 14/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0607 - acc: 0.9185\n",
      "Epoch 15/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0592 - acc: 0.9188\n",
      "Epoch 16/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0582 - acc: 0.9207\n",
      "Epoch 17/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0568 - acc: 0.9229\n",
      "Epoch 18/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0563 - acc: 0.9247\n",
      "Epoch 19/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0563 - acc: 0.9235\n",
      "Epoch 20/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0550 - acc: 0.9248\n",
      "Epoch 21/350\n",
      "8248/8248 [==============================] - 15s 2ms/step - loss: 0.0543 - acc: 0.9282\n",
      "Epoch 22/350\n",
      "5610/8248 [===================>..........] - ETA: 4s - loss: 0.0513 - acc: 0.9298"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_data,y_data,\n",
    "          batch_size=30,epochs=350,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.2387199e-07]\n",
      " [1.0816157e-03]\n",
      " [6.9976151e-03]\n",
      " ...\n",
      " [2.0861626e-07]\n",
      " [1.5318990e-03]\n",
      " [9.7423065e-01]]\n",
      "             Label\n",
      "Id                \n",
      "0     9.238720e-07\n",
      "1     1.081616e-03\n",
      "2     6.997615e-03\n",
      "3     0.000000e+00\n",
      "4     3.576279e-07\n",
      "...            ...\n",
      "3992  9.048820e-03\n",
      "3993  2.980232e-08\n",
      "3994  2.086163e-07\n",
      "3995  1.531899e-03\n",
      "3996  9.742306e-01\n",
      "\n",
      "[3997 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(test_data);\n",
    "print(Y_pred)\n",
    "df_pred = pd.DataFrame(Y_pred);\n",
    "df_pred.index.name = \"Id\"\n",
    "df_pred = pd.DataFrame.rename(df_pred,columns={0:\"Label\"})\n",
    "print(df_pred);\n",
    "df_pred.to_csv(\"output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
